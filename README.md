# Retrieval-Augmented Generation (RAG) System
> *Advanced Document Retrieval & Question Answering System implemented for ADL HW3*

é€™æ˜¯ä¸€å€‹é«˜æ•ˆèƒ½çš„ **RAG (Retrieval-Augmented Generation)** ç³»çµ±ï¼Œçµåˆäº† **Bi-Encoder** é€²è¡Œå¿«é€Ÿåˆæ­¥æª¢ç´¢èˆ‡ **Cross-Encoder** é€²è¡Œç²¾ç¢ºé‡æ’åºï¼Œä¸¦é€éå„ªåŒ–çš„ **Prompt Engineering** å¼•å° LLM ç”Ÿæˆæº–ç¢ºç­”æ¡ˆã€‚

## ğŸ“‹ ç›®éŒ„

- [å°ˆæ¡ˆæˆæœ (Key Results)](#-å°ˆæ¡ˆæˆæœ-key-results)
- [æ–¹æ³•è«– (Methodology)](#-æ–¹æ³•è«–-methodology)
- [æ¶ˆèå¯¦é©— (Ablation Study)](#q3-æ¶ˆèå¯¦é©—-ablation-study)
- [è©³ç´°æ¨¡å‹è¨“ç·´ (Detailed Training)](#è©³ç´°æ¨¡å‹è¨“ç·´)
- [æ¨¡å‹æ¨è«– (Inference)](#æ¨¡å‹æ¨è«–)
- [å°ˆæ¡ˆçµæ§‹ (Project Structure)](#å°ˆæ¡ˆçµæ§‹)
- [é‡è¦æé†’ (Data Download)](#-é‡è¦æé†’)
- [ç’°å¢ƒè¨­å®š (Environment)](#ç’°å¢ƒè¨­å®š)
- [åƒè€ƒè³‡æ–™](#åƒè€ƒè³‡æ–™)

---

## ğŸ† å°ˆæ¡ˆæˆæœ (Key Results)

æœ¬ç³»çµ±åœ¨æ¸¬è©¦é›†ä¸Šå±•ç¾äº†å„ªç•°çš„æª¢ç´¢èˆ‡ç”Ÿæˆèƒ½åŠ›ï¼Œé€éå…©éšæ®µæª¢ç´¢æ¶æ§‹é¡¯è‘—æå‡äº†æº–ç¢ºåº¦ã€‚

| Metric | Score | Description |
|--------|-------|-------------|
| **Recall@10** | **0.8900** | Retriever æˆåŠŸåœ¨å‰ 10 ç­†ä¸­æ‰¾å›æ­£ç¢ºæ–‡æª”çš„æ¯”ä¾‹ |
| **MRR@10** | **0.7745** | åŠ å…¥ Reranker å¾Œï¼Œæ­£ç¢ºæ–‡æª”çš„å¹³å‡å€’æ•¸æ’åé¡¯è‘—æå‡ (+16.7%) |
| **CosSim** | **0.4143** | ç”Ÿæˆç­”æ¡ˆèˆ‡æ¨™æº–ç­”æ¡ˆçš„èªæ„ç›¸ä¼¼åº¦ |

---

## ğŸ“– æ–¹æ³•è«– (Methodology)

æœ¬å°ˆæ¡ˆæ¡ç”¨å…©éšæ®µæª¢ç´¢ç­–ç•¥ (Two-Stage Retrieval)ï¼Œæµç¨‹å¦‚ä¸‹ï¼š
1. **Retriever**: å¾æµ·é‡æ–‡æª”ä¸­å¿«é€Ÿç¯©é¸ Top-100 å€™é¸ã€‚
2. **Reranker**: å°å€™é¸æ–‡æª”é€²è¡Œç²¾ç´°è©•åˆ†æ’åºï¼Œé¸å‡º Top-5ã€‚
3. **Reader (LLM)**: æ ¹æ“š Top-5 æ–‡æª”ç”Ÿæˆæœ€çµ‚ç­”æ¡ˆã€‚

### 1. Retriever: Bi-Encoder Training
æˆ‘ä½¿ç”¨ `intfloat/multilingual-e5-small` ä½œç‚ºåŸºåº•æ¨¡å‹ï¼Œæ¡ç”¨ **MultipleNegativesRankingLoss (MNRL)** é€²è¡Œå¾®èª¿ã€‚

- **è¨“ç·´ç­–ç•¥**:
    - **Anchor**: é‡å¯«å¾Œçš„æŸ¥è©¢ (Rewrite Query)
    - **Positive**: æ¨™è¨»ç‚ºç›¸é—œçš„æ–‡æª”
    - **Negative**: åŒä¸€å€‹ Batch ä¸­çš„å…¶ä»–æ–‡æª” (In-batch negatives) + ç¡¬è² æ¨£æœ¬ (Hard negatives)
- **è¨“ç·´æˆæ•ˆ**:
    - Loss å¾åˆå§‹çš„ 0.85 è¿…é€Ÿæ”¶æ–‚è‡³ 0.06ï¼Œé¡¯ç¤ºæ¨¡å‹æœ‰æ•ˆå­¸ç¿’åˆ°äº†èªæ„åŒ¹é…é—œä¿‚ã€‚
    - æœ€çµ‚ Recall@10 é”åˆ° **0.8677**ã€‚

![Retriever Training Loss](training_loss_curve.png)
*åœ– 1: Bi-Encoder è¨“ç·´æå¤±æ”¶æ–‚æ›²ç·š*


> [!TIP]
> **è¨“ç·´ç™¼ç¾**: ç™¼ç¾äº†åœ¨è¨“ç·´ä¸­æœƒéæ“¬åˆ (Overfitting)ï¼Œæˆ‘ç™¼ç¾è¨“ç·´ **1 å€‹ Epoch** çš„æ•ˆæœæœ€ä½³ï¼Œéå¤šçš„è¨“ç·´åè€Œæœƒå°è‡´é©—è­‰é›†è¡¨ç¾ä¸‹é™ã€‚

### 2. Reranker: Cross-Encoder Optimization
æˆ‘æ¯”è¼ƒäº†ã€Œå¾®èª¿æ¨¡å‹ã€èˆ‡ã€Œé è¨“ç·´æ¨¡å‹ã€çš„æ•ˆæœã€‚

- **æ¨¡å‹æ¶æ§‹**: `cross-encoder/ms-marco-MiniLM-L-12-v2`
- **å¯¦é©—ç™¼ç¾**:
    - **å¾®èª¿å˜—è©¦**: ä½¿ç”¨ Weighted BCE Loss é€²è¡Œè¨“ç·´ï¼Œä½†ç™¼ç¾ç”±æ–¼è³‡æ–™é‡é™åˆ¶ï¼Œå¾®èª¿å¾Œçš„ MRR@10 (0.2011) åè€Œä¸å¦‚é è¨“ç·´æ¨¡å‹ã€‚
    - **æœ€çµ‚æ±ºç­–**: ç›´æ¥æ¡ç”¨ **é è¨“ç·´æ¨¡å‹**ï¼Œç²å¾—äº†æœ€ä½³çš„ MRR@10 (**0.7558**)ã€‚é€™è­‰å¯¦äº†åœ¨ç‰¹å®šè³‡æ–™é›†è¼ƒå°çš„æƒ…æ³ä¸‹ï¼Œå¼·å¤§çš„é€šç”¨é è¨“ç·´æ¨¡å‹å¾€å¾€æ›´å…·å„ªå‹¢ã€‚

![Reranker Performance](reranker_training_loss_3.png)
*åœ– 2: Reranker è¨“ç·´èˆ‡é©—è­‰æå¤±åˆ†æ*


### 3. Prompt Engineering (LLM)
ç‚ºäº†è®“ LLM (Claude/GPT) ç”Ÿæˆç²¾æº–ç­”æ¡ˆï¼Œæˆ‘é€²è¡Œäº†å¤šè¼ª Prompt å„ªåŒ–ï¼š

- **v1 (Initial)**: è¨­å®šè§’è‰² ("precise question-answering assistant") ä¸¦é™åˆ¶ "based ONLY on the given context"ã€‚
- **v2 (Simplified)**: å˜—è©¦ç°¡åŒ–æŒ‡ä»¤ï¼Œä½†ç™¼ç¾æ¨¡å‹å®¹æ˜“ç”¢ç”Ÿå¹»è¦ºæˆ–æ ¼å¼éŒ¯èª¤ã€‚
- **v3 (Final)**: 
    - åŠ å…¥ **çµæ§‹åŒ–è¼¸å…¥** (`[Passage 1]`, `[Passage 2]`)ã€‚
    - å¼·åˆ¶ **"One Answer"** é™åˆ¶ï¼Œé¿å…é‡å°æ¯å€‹æ®µè½åˆ†åˆ¥å›ç­”ã€‚
    - å„ªåŒ– **Answer Parsing** é‚è¼¯ï¼Œæº–ç¢ºéæ¿¾ "The answer is:" ç­‰è´…è©ã€‚
    - **çµæœ**: é…åˆ Rerankerï¼Œæœ€çµ‚ Cosine Similarity é”åˆ° **0.4143**ã€‚

#### æœ€ä½³ Prompt æ ¼å¼ (Best Prompt Format)

æœ€çµ‚æ¡ç”¨çš„ Prompt æ ¼å¼å¦‚ä¸‹ï¼Œå¼·èª¿äº†ã€Œç²¾ç¢ºå¼•ç”¨ã€èˆ‡ã€Œå–®ä¸€ç­”æ¡ˆã€çš„é™åˆ¶ï¼š

```text
Context passages:
[1] <passage_content_1>
[2] <passage_content_2>
...

Question: <query>

Instructions:
1. Read all passages carefully to find the only answer
2. Your answer MUST be copied EXACTLY from the passage text - do NOT paraphrase or change any words
3. Copy the relevant sentence(s) word-for-word from the passage
4. If the answer is not found in any passage, write exactly: CANNOTANSWER

Answer:
```

é—œæ–¼ LLM ç”Ÿæˆå¾Œçš„ç­”æ¡ˆè§£æèˆ‡éæ¿¾ç¨‹å¼ç¢¼ï¼Œè«‹åƒè€ƒ [utils.py](utils.py)ã€‚


---

## ğŸ”¬ æ·±å…¥å¯¦é©—åˆ†æï¼šæ¶ˆèç ”ç©¶ (Ablation Study)

ç‚ºäº†é©—è­‰ä¸Šè¿° **å…©éšæ®µæª¢ç´¢æ¶æ§‹ (Two-Stage Retrieval)** çš„å¿…è¦æ€§ï¼Œä¸¦æ¢è¨ **Reranker** èˆ‡ **æª¢ç´¢æ•¸é‡ (Top-K)** å°æœ€çµ‚ RAG ç³»çµ±æ•ˆèƒ½çš„å…·é«”å½±éŸ¿ï¼Œæˆ‘è¨­è¨ˆäº†ä»¥ä¸‹æ¶ˆèå¯¦é©—ã€‚

### å¯¦é©—ç›®çš„

åˆ†æé—œéµçµ„ä»¶å°æª¢ç´¢æ•ˆèƒ½çš„è²¢ç»ï¼š
1. **Reranker çš„å¿…è¦æ€§**: æ¯”è¼ƒæ˜¯å¦åŠ å…¥ Reranker å° MRR (Mean Reciprocal Rank) çš„æå‡å¹…åº¦ã€‚
2. **æ•¸é‡ vs å“è³ª**: æ¸¬è©¦å–®ç´”å¢åŠ  Retriever çš„æª¢ç´¢æ•¸é‡ (Top-K)ï¼Œæ˜¯å¦èƒ½å½Œè£œç§»é™¤ Reranker å¾Œçš„æ•ˆèƒ½æå¤±ã€‚

### å¯¦é©—è¨­è¨ˆ

è¨­è¨ˆäº†ä¸‰çµ„å°ç…§å¯¦é©—:

| å¯¦é©—çµ„ | é…ç½® | èªªæ˜ |
|--------|------|------|
| **å¯¦é©— 1** | Retriever Only (Top 3) | åªç”¨ Retriever,å–å‰ 3 åç›´æ¥é€å…¥ LLM |
| **å¯¦é©— 2** | Retriever + Reranker (Top 3) | ä½¿ç”¨ Reranker é‡æ’å¾Œ,å–å‰ 3 åé€å…¥ LLM |
| **å¯¦é©— 3** | Retriever Only (Top 5) | åªç”¨ Retriever,ä½†å¢åŠ åˆ°å‰ 5 åé€å…¥ LLM |

### åŸ·è¡Œå¯¦é©—

ä½¿ç”¨ `inference_ablation.py` è…³æœ¬é€²è¡Œæ¶ˆèå¯¦é©—:

```bash
# åŸ·è¡Œæ‰€æœ‰å¯¦é©— (æ¨è–¦)
python inference_ablation.py --mode all

# æˆ–åˆ†åˆ¥åŸ·è¡Œå–®ä¸€å¯¦é©—
python inference_ablation.py --mode retriever_only    # åªåŸ·è¡Œå¯¦é©— 1
python inference_ablation.py --mode with_reranker     # åªåŸ·è¡Œå¯¦é©— 2
python inference_ablation.py --mode retriever_more    # åªåŸ·è¡Œå¯¦é©— 3
```

### å¯¦é©—çµæœ

å¯¦é©—çµæœæœƒå„²å­˜åœ¨ `results/` ç›®éŒ„ä¸‹:
- `ablation_retriever_only_top3.json` - å¯¦é©— 1 çµæœ
- `ablation_with_reranker_top3.json` - å¯¦é©— 2 çµæœ
- `ablation_retriever_only_top5.json` - å¯¦é©— 3 çµæœ
- `ablation_summary.json` - å¯¦é©—ç¸½çµ

### é æœŸåˆ†ææ–¹å‘

**å•é¡Œ 1: Reranker æ˜¯å¦èƒ½æ˜é¡¯æå‡ MRR?**
- æ¯”è¼ƒå¯¦é©— 1 vs å¯¦é©— 2 çš„ MRR@10 å·®ç•°
- åˆ†æ Reranker å°æ’åºå“è³ªçš„å½±éŸ¿
- è§€å¯Ÿæœ‰ç„¡ Reranker å°æœ€çµ‚ç­”æ¡ˆç”Ÿæˆçš„å½±éŸ¿

**å•é¡Œ 2: å¢åŠ è¼¸å…¥ç­†æ•¸èƒ½å¦å½Œè£œæ²’æœ‰ Reranker?**
- æ¯”è¼ƒå¯¦é©— 1 (Top 3) vs å¯¦é©— 3 (Top 5)
- æ¯”è¼ƒå¯¦é©— 2 (Reranker + Top 3) vs å¯¦é©— 3 (Retriever Only + Top 5)
- åˆ†æã€Œé‡ã€(æ›´å¤šå€™é¸) æ˜¯å¦èƒ½è£œå„Ÿã€Œè³ªã€(Reranker é‡æ’)

### å¯¦é©—çµæœèˆ‡åˆ†æ

æˆ‘åœ¨ 100 ç­†æ¸¬è©¦è³‡æ–™ä¸Šé€²è¡Œäº†æ¶ˆèå¯¦é©—,æ¸¬è©¦çµæœå¦‚ä¸‹:

#### å¯¦é©—æ•¸æ“š

| å¯¦é©—é…ç½® | Recall@10 | MRR@10 | Bi-Encoder CosSim |
|---------|-----------|--------|-------------------|
| **å¯¦é©— 1**: Retriever Only (Top 3) | 0.8900 | 0.6633 | 0.4026 |
| **å¯¦é©— 2**: Retriever + Reranker (Top 3) | 0.8900 | 0.7745 | 0.4143 |
| **å¯¦é©— 3**: Retriever Only (Top 5) | 0.8900 | 0.6633 | 0.4131 |
| **å¯¦é©— 4**: Retriever Only (Top 8) | 0.8900 | 0.6633 | 0.4039 |

#### é—œéµç™¼ç¾

**1. Reranker çš„å½±éŸ¿**
- **MRR@10 æå‡**: å¾ 0.6633 æå‡è‡³ 0.7745 (+16.77%)
- **Bi-Encoder CosSim æå‡**: å¾ 0.4026 æå‡è‡³ 0.4143 (+2.91%)
- **çµè«–**: Reranker èƒ½é¡¯è‘—æå‡ç›¸é—œæ–‡æª”çš„æ’åºå“è³ª,ä½¿æ­£ç¢ºç­”æ¡ˆæ›´å®¹æ˜“è¢« LLM è­˜åˆ¥

**2. å¢åŠ è¼¸å…¥ç­†æ•¸çš„æ•ˆæœ**
- **Top 3 â†’ Top 5**: Bi-Encoder CosSim å¾ 0.4026 æå‡è‡³ 0.4131 (+2.61%)
- **Top 5 â†’ Top 8**: Bi-Encoder CosSim å¾ 0.4131 ä¸‹é™è‡³ 0.4039 (-2.23%)
- **çµè«–**: é©åº¦å¢åŠ è¼¸å…¥ç­†æ•¸ (Top 5) èƒ½æå‡æ•ˆæœ,ä½†éå¤š (Top 8) åè€Œé™ä½ LLM åˆ¤æ–·æº–ç¢ºåº¦

**3. èƒ½å¦ç”¨å¢åŠ è¼¸å…¥ç­†æ•¸å½Œè£œæ²’æœ‰ Reranker?**
- **Retriever + Reranker (Top 3)**: CosSim = 0.4143
- **Retriever Only (Top 5)**: CosSim = 0.4131
- **å·®è·**: åƒ… 0.0012 (0.29%)
- **çµè«–**: âœ… **å¯ä»¥!** Top 5 å¹¾ä¹å®Œå…¨å½Œè£œäº†æ²’æœ‰ Reranker çš„å½±éŸ¿

#### æ·±å…¥åˆ†æ

**ç‚ºä»€éº¼å¢åŠ ç­†æ•¸èƒ½å½Œè£œ Reranker?**
1. **LLM çš„å…¨æ–‡é–±è®€ç‰¹æ€§**: LLM æœƒè®€å–æ‰€æœ‰è¼¸å…¥çš„åƒè€ƒæ–‡ç« ,ä¸¦ä¸ä¾è³´é †åº
2. **æç¤ºè©çš„é‡è¦æ€§**: è‰¯å¥½çš„æç¤ºè©èƒ½å¼•å° LLM å¾å¤šç¯‡æ–‡ç« ä¸­æå–æ­£ç¢ºè³‡è¨Š
3. **è³‡è¨Šè¦†è“‹ç‡**: Top 5 å¢åŠ äº†åŒ…å«æ­£ç¢ºç­”æ¡ˆçš„æ©Ÿç‡,å³ä½¿æ’åºä¸ä½³ä¹Ÿèƒ½è¢« LLM æ‰¾åˆ°

**ç‚ºä»€éº¼ Top 8 åè€Œè®Šå·®?**
1. **è³‡è¨Šéè¼‰**: éå¤šçš„åƒè€ƒæ–‡ç« å¯èƒ½é€ æˆ LLM æ³¨æ„åŠ›åˆ†æ•£
2. **é›œè¨Šå¢åŠ **: Top 8 åŒ…å«æ›´å¤šä¸ç›¸é—œæ–‡ç« ,å¹²æ“¾ LLM åˆ¤æ–·
3. **æœ€ä½³å¹³è¡¡é»**: å°æ–¼æ­¤ä»»å‹™,Top 5 æ˜¯è³‡è¨Šé‡èˆ‡å“è³ªçš„æœ€ä½³å¹³è¡¡

#### å¯¦å‹™å»ºè­°

**æƒ…å¢ƒ 1: è¿½æ±‚æœ€é«˜æº–ç¢ºåº¦**
- ä½¿ç”¨ **Retriever + Reranker (Top 3)**
- MRR@10: 0.7745 (æœ€é«˜)
- Bi-Encoder CosSim: 0.4143 (æœ€é«˜)
- è¨ˆç®—æˆæœ¬: è¼ƒé«˜ (éœ€åŸ·è¡Œ Cross-Encoder)

**æƒ…å¢ƒ 2: å¹³è¡¡æ•ˆèƒ½èˆ‡æº–ç¢ºåº¦** â­ **æ¨è–¦**
- ä½¿ç”¨ **Retriever Only (Top 5)**
- Bi-Encoder CosSim: 0.4131 (æ¥è¿‘æœ€é«˜)
- è¨ˆç®—æˆæœ¬: ä½ (åƒ…éœ€ Bi-Encoder)
- **æ•ˆèƒ½æå‡**: çœå» Reranker è¨ˆç®—,æ¨è«–é€Ÿåº¦æå‡ ~50%

**æƒ…å¢ƒ 3: æ¥µè‡´æ•ˆèƒ½å„ªå…ˆ**
- ä½¿ç”¨ **Retriever Only (Top 3)**
- Bi-Encoder CosSim: 0.4026 (å¯æ¥å—)
- è¨ˆç®—æˆæœ¬: æœ€ä½
- é©åˆå³æ™‚æ€§è¦æ±‚æ¥µé«˜çš„æ‡‰ç”¨

#### æœ€çµ‚çµè«–

> **åœ¨å…·å‚™è‰¯å¥½æç¤ºè©çš„å‰æä¸‹,ä½¿ç”¨ Retriever Only (Top 5) æ˜¯æœ€ä½³é¸æ“‡!**
> 
> æ­¤é…ç½®å¯ä»¥:
> - âœ… å¹¾ä¹é”åˆ° Reranker çš„æ•ˆæœ (å·®è·åƒ… 0.29%)
> - âœ… é™ä½è¨ˆç®—æˆæœ¬ (çœå» Cross-Encoder é‹ç®—)
> - âœ… ç°¡åŒ–ç³»çµ±æ¶æ§‹ (å–®ä¸€æ¨¡å‹)

---

## è©³ç´°æ¨¡å‹è¨“ç·´

### 1. Retriever æ¨¡å‹è¨“ç·´

Retriever ä½¿ç”¨ **Bi-Encoder** æ¶æ§‹,å°‡æŸ¥è©¢å’Œæ–‡æª”åˆ†åˆ¥ç·¨ç¢¼ç‚ºå‘é‡,é€éå‘é‡ç›¸ä¼¼åº¦å¿«é€Ÿæª¢ç´¢å€™é¸æ–‡æª”ã€‚

#### è¨“ç·´è³‡æ–™æ§‹å»º

**è³‡æ–™ä¾†æº**: `data/train.txt`

**æ¡æ¨£ç­–ç•¥**:
- **Anchor (éŒ¨é»)**: ä½¿ç”¨ `rewrite` æ¬„ä½ä½œç‚ºæŸ¥è©¢æ–‡æœ¬
- **Positive (æ­£æ¨£æœ¬)**: å¾ `evidences` ä¸­é¸å– `retrieval_labels == 1` çš„æ®µè½ (~1 å€‹/æŸ¥è©¢)
- **Negative (è² æ¨£æœ¬)**: å¾ `evidences` ä¸­é¸å– `retrieval_labels == 0` çš„æ®µè½ (~4 å€‹/æŸ¥è©¢)

**è¨“ç·´ä¸‰å…ƒçµ„ç”Ÿæˆ**:
```
å°æ–¼æ¯å€‹æŸ¥è©¢:
  å°æ–¼æ¯å€‹æ­£æ¨£æœ¬:
    å°æ–¼æ¯å€‹è² æ¨£æœ¬:
      å»ºç«‹ (query, positive, negative) ä¸‰å…ƒçµ„
```
- ä¸€å€‹æŸ¥è©¢è‹¥æœ‰ 1 å€‹æ­£æ¨£æœ¬å’Œ 4 å€‹è² æ¨£æœ¬,æœƒç”Ÿæˆ **1Ã—4 = 4 å€‹è¨“ç·´æ¨£æœ¬**

#### æå¤±å‡½æ•¸

ä½¿ç”¨ **MultipleNegativesRankingLoss (MNRL)**:

$$
\mathcal{L} = -\log\frac{\exp(\text{sim}(q, p^+) / \tau)}{\sum_{i} \exp(\text{sim}(q, p_i) / \tau)}
$$

å…¶ä¸­:
- $q$: æŸ¥è©¢åµŒå…¥å‘é‡
- $p^+$: æ­£æ¨£æœ¬åµŒå…¥å‘é‡
- $p_i$: æ‰€æœ‰å€™é¸æ®µè½ (åŒ…å«æ­£è² æ¨£æœ¬åŠ batch å…§å…¶ä»–æ¨£æœ¬)
- $\tau$: æº«åº¦åƒæ•¸

**å„ªå‹¢**:
- åˆ©ç”¨ batch å…§å…¶ä»–æ¨£æœ¬ä½œç‚ºé¡å¤–è² æ¨£æœ¬
- è¨ˆç®—æ•ˆç‡é«˜,é©åˆå¤§è¦æ¨¡è¨“ç·´
- è‡ªå‹•å½¢æˆå›°é›£è² æ¨£æœ¬,æå‡è¾¨è­˜èƒ½åŠ›

#### è¶…åƒæ•¸è¨­å®š

| è¶…åƒæ•¸ | æ•¸å€¼ | èªªæ˜ |
|--------|------|------|
| `model_name` | `intfloat/multilingual-e5-small` | é è¨“ç·´æ¨¡å‹ |
| `max_seq_length` | 512 | æœ€å¤§åºåˆ—é•·åº¦ |
| `train_batch_size` | 64 | è¨“ç·´æ‰¹æ¬¡å¤§å° |
| `num_epochs` | 3 | è¨“ç·´è¼ªæ•¸ |
| `learning_rate` | 2e-5 | å­¸ç¿’ç‡ |
| `warmup_steps` | 500 | å­¸ç¿’ç‡é ç†±æ­¥æ•¸ |
| `use_amp` | True | ä½¿ç”¨æ··åˆç²¾åº¦è¨“ç·´ |

#### åŸ·è¡Œè¨“ç·´

```bash
python train_bi-encoder_mnrl_with_logging.py \
    --model_name intfloat/multilingual-e5-small \
    --use_pre_trained_model \
    --epochs 3 \
    --train_batch_size 64 \
    --max_seq_length 512 \
    --log_every_n_steps 50
```

#### è¼¸å‡ºæª”æ¡ˆ

è¨“ç·´å®Œæˆå¾Œ,æ¨¡å‹å’Œç›¸é—œæª”æ¡ˆæœƒå„²å­˜åœ¨:
```
output/train_bi-encoder-mnrl-intfloat-multilingual-e5-small-{timestamp}/
â”œâ”€â”€ config.json                    # æ¨¡å‹é…ç½®
â”œâ”€â”€ pytorch_model.bin              # æ¨¡å‹æ¬Šé‡
â”œâ”€â”€ training_loss_curve.png        # è¨“ç·´æå¤±æ›²ç·šåœ–
â”œâ”€â”€ training_loss_history.json     # æå¤±æ•¸æ“šè¨˜éŒ„
â””â”€â”€ training_config.json           # è¨“ç·´é…ç½®
```

---

### 2. Reranker æ¨¡å‹è¨“ç·´

Reranker ä½¿ç”¨ **Cross-Encoder** æ¶æ§‹,å°‡æŸ¥è©¢å’Œæ–‡æª”ä¸€èµ·è¼¸å…¥æ¨¡å‹,è¼¸å‡ºç›¸é—œæ€§åˆ†æ•¸ä»¥é‡æ–°æ’åºæª¢ç´¢çµæœã€‚

#### è¨“ç·´è³‡æ–™æ§‹å»º

**è³‡æ–™ä¾†æº**: `data/train.txt`

**æ¡æ¨£ç­–ç•¥**:
- **Anchor (éŒ¨é»)**: `rewrite` æ¬„ä½ä½œç‚ºæŸ¥è©¢
- **Positive (æ­£æ¨£æœ¬)**: `retrieval_labels == 1` çš„ evidence (~1 å€‹/æŸ¥è©¢)
- **Negative (è² æ¨£æœ¬)**: `retrieval_labels == 0` çš„ evidence (~4 å€‹/æŸ¥è©¢)

**è³‡æ–™è™•ç†**:
```python
å°æ–¼æ¯å€‹æŸ¥è©¢:
  å°æ–¼æ¯å€‹ (evidence, label) é…å°:
    å»ºç«‹ (query, passage, label) ä¸‰å…ƒçµ„
```
- æ¯å€‹æŸ¥è©¢ç”Ÿæˆç´„ 5 å€‹è¨“ç·´æ¨£æœ¬ (1 æ­£ + 4 è² )

#### æå¤±å‡½æ•¸

ä½¿ç”¨ **Binary Cross-Entropy Loss (BCE)** åŠ æ¬Šç‰ˆæœ¬:

$$
\mathcal{L}_{\text{weighted}}(y, \hat{y}) = -[w_{\text{pos}} \cdot y \cdot \log(\hat{y}) + (1-y) \cdot \log(1-\hat{y})]
$$

å…¶ä¸­:
- $y \in \{0, 1\}$: çœŸå¯¦æ¨™ç±¤
- $\hat{y} = \sigma(f(q, p))$: æ¨¡å‹é æ¸¬çš„ç›¸é—œæ€§åˆ†æ•¸ (ç¶“é sigmoid)
- $w_{\text{pos}} = \frac{\text{è² æ¨£æœ¬æ•¸}}{\text{æ­£æ¨£æœ¬æ•¸}} \approx 4.0$: æ­£æ¨£æœ¬æ¬Šé‡

**ç‚ºä»€éº¼é¸æ“‡ BCE Loss**:
1. é©åˆäºŒåˆ†é¡ä»»å‹™ (ç›¸é—œ/ä¸ç›¸é—œ)
2. è¼¸å‡º 0-1 çš„ç›¸é—œæ€§æ©Ÿç‡åˆ†æ•¸
3. é€é `pos_weight` è™•ç†é¡åˆ¥ä¸å¹³è¡¡å•é¡Œ
4. åœ¨è³‡è¨Šæª¢ç´¢ä»»å‹™ä¸­è¢«å»£æ³›é©—è­‰æœ‰æ•ˆ

#### è¶…åƒæ•¸è¨­å®š

| è¶…åƒæ•¸ | æ•¸å€¼ | èªªæ˜ |
|--------|------|------|
| `model_name` | `cross-encoder/ms-marco-MiniLM-L-12-v2` | åŸºç¤æ¨¡å‹ |
| `num_labels` | 1 | è¼¸å‡ºç¶­åº¦ (ç›¸é—œæ€§åˆ†æ•¸) |
| `train_batch_size` | 64 | è¨“ç·´æ‰¹æ¬¡å¤§å° |
| `num_epochs` | 2 | è¨“ç·´è¼ªæ•¸ |
| `learning_rate` | 5e-6 | å­¸ç¿’ç‡ |
| `warmup_ratio` | 0.1 | Warmup æ¯”ä¾‹ (å‰ 10% steps) |
| `validation_ratio` | 0.05 | é©—è­‰é›†æ¯”ä¾‹ (5%) |
| `pos_weight` | ~4.0 | æ­£æ¨£æœ¬æ¬Šé‡ (å‹•æ…‹è¨ˆç®—) |

#### åŸ·è¡Œè¨“ç·´

```bash
python train_reranker.py
```

#### è¼¸å‡ºæª”æ¡ˆ

è¨“ç·´å®Œæˆå¾Œ,æ¨¡å‹å’Œç›¸é—œæª”æ¡ˆæœƒå„²å­˜åœ¨:
```
models/reranker-ms-marco-MiniLM-L-12-v2-hw3-val/
â”œâ”€â”€ final/                              # æœ€çµ‚æ¨¡å‹
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ model.safetensors
â”‚   â””â”€â”€ ...
â”œâ”€â”€ training_validation_loss.png        # è¨“ç·´èˆ‡é©—è­‰æå¤±æ›²ç·š
â”œâ”€â”€ trainer_state.json                  # è¨“ç·´ç‹€æ…‹
â””â”€â”€ checkpoint-*/                       # è¨“ç·´éç¨‹ checkpoints
```

---

## æ¨¡å‹æ¨è«–

### 0. ä¸‹è¼‰è¨“ç·´å¥½çš„æ¨¡å‹ (é‡è¦!)

åŸ·è¡Œ `download.sh` è…³æœ¬ä¾†ä¸‹è¼‰è¨“ç·´å¥½çš„æ¨¡å‹ï¼š

```bash
bash download.sh
```

æ­¤è…³æœ¬æœƒè‡ªå‹•ï¼š
1. å¾ Google Drive ä¸‹è¼‰è¨“ç·´å¥½çš„æ¨¡å‹å£“ç¸®æª”
2. è§£å£“ç¸®æ¨¡å‹åˆ°æ­£ç¢ºçš„ç›®éŒ„
3. è¨­å®šå¥½ `models/retriever/` å’Œ `models/reranker/` ç›®éŒ„

**æ³¨æ„**: 
- Retriever æ¨¡å‹ç‚ºè¨“ç·´ 1 epoch çš„ç‰ˆæœ¬ (é¿å…éæ“¬åˆ)
- Reranker æ¨¡å‹ç‚ºé è¨“ç·´çš„ `cross-encoder/ms-marco-MiniLM-L-12-v2` (æ•ˆæœæœ€ä½³)

### 1. å»ºç«‹å‘é‡è³‡æ–™åº«

åœ¨é€²è¡Œæ¨è«–å‰,éœ€è¦å…ˆå°‡ `corpus.txt` ä¸­çš„æ–‡æª”ç·¨ç¢¼ä¸¦å„²å­˜ç‚ºå‘é‡è³‡æ–™åº«:

```bash
python save_embeddings.py \
    --retriever_model_path ./models/retriever \
    --build_db
```

### 2. è¨­å®š Hugging Face Token

å»ºç«‹ `.env` æª”æ¡ˆä¸¦åŠ å…¥ä½ çš„ Hugging Face token:

```bash
echo 'hf_token="your_huggingface_token_here"' > .env
```

ç²å– token: [https://huggingface.co/docs/hub/security-tokens](https://huggingface.co/docs/hub/security-tokens)

### 3. åŸ·è¡Œæ¨è«–

**ä½¿ç”¨æœ¬åœ°ä¸‹è¼‰çš„é è¨“ç·´ Reranker æ¨¡å‹** (æ¨è–¦):

```bash
python inference_batch.py \
    --test_data_path ./data/test_open.txt \
    --retriever_model_path ./models/retriever \
    --reranker_model_path ./models/reranker
```

**æˆ–ç›´æ¥ä½¿ç”¨ç·šä¸Šé è¨“ç·´æ¨¡å‹** (éœ€è¦ç¶²è·¯é€£ç·š):

```bash
python inference_batch.py \
    --test_data_path ./data/test_open.txt \
    --retriever_model_path ./models/retriever \
    --reranker_model_path cross-encoder/ms-marco-MiniLM-L-12-v2
```

**æ¨è«–æµç¨‹**:
1. **Retriever éšæ®µ**: ä½¿ç”¨ Bi-Encoder å¾ corpus ä¸­å¿«é€Ÿæª¢ç´¢ top-K å€™é¸æ–‡æª”
2. **Reranker éšæ®µ**: ä½¿ç”¨ Cross-Encoder å°å€™é¸æ–‡æª”é‡æ–°æ’åº,è¼¸å‡ºæœ€ç›¸é—œçš„çµæœ

### è¼¸å‡ºæ ¼å¼

æ¨è«–çµæœæœƒå„²å­˜åœ¨ `results/result.json`:
```json
{
    "query_id_1": "retrieved_passage_text_1",
    "query_id_2": "retrieved_passage_text_2",
    ...
}
```

---

## å°ˆæ¡ˆçµæ§‹

```
ADL/HW3/
â”œâ”€â”€ results/                # æ¨è«–çµæœ
â”œâ”€â”€ download.sh             # æ¨¡å‹ä¸‹è¼‰è…³æœ¬
â”œâ”€â”€ download_pretrained_reranker.py
â”œâ”€â”€ inference_ablation.py   # Q3 æ¶ˆèå¯¦é©—
â”œâ”€â”€ inference_batch.py      # ä¸»è¦æ¨è«–è…³æœ¬
â”œâ”€â”€ plot_training_log.py    # ç¹ªåœ–å·¥å…·
â”œâ”€â”€ requirements.txt        # å¥—ä»¶éœ€æ±‚
â”œâ”€â”€ run_ablation.sh         # åŸ·è¡Œæ¶ˆèå¯¦é©—è…³æœ¬
â”œâ”€â”€ save_embeddings.py      # å»ºç«‹å‘é‡è³‡æ–™åº«
â”œâ”€â”€ train_bi-encoder_mnrl_with_logging.py # Retriever è¨“ç·´
â”œâ”€â”€ train_reranker.py       # Reranker è¨“ç·´
â”œâ”€â”€ utils.py                # å·¥å…·å‡½å¼
â”œâ”€â”€ README.md               # æœ¬æ–‡ä»¶
â”œâ”€â”€ report.pdf              # ä½œæ¥­å ±å‘Š
â”œâ”€â”€ retrieveræ¨¡å‹è¨“ç·´èªªæ˜.md
â””â”€â”€ rerankerè¨“ç·´èªªæ˜.md
```

---

## âš ï¸ é‡è¦æé†’

### æ•¸æ“šæ–‡ä»¶ä¸‹è¼‰

ç”±æ–¼ `data/` è³‡æ–™å¤¾ä¸­çš„æª”æ¡ˆéå¤§ï¼ˆè¶…é GitHub 100MB é™åˆ¶ï¼‰ï¼Œå› æ­¤æœªåŒ…å«åœ¨æ­¤å„²å­˜åº«ä¸­ã€‚

**è«‹å¾ä»¥ä¸‹é€£çµä¸‹è¼‰å®Œæ•´çš„æ•¸æ“šè³‡æ–™å¤¾ï¼š**

ğŸ”— [Google Drive - Data è³‡æ–™å¤¾](https://drive.google.com/drive/folders/1v5hSQYPyQuUnzaE1Lp3F1vejNazW48TH?usp=sharing)

ä¸‹è¼‰å¾Œï¼Œè«‹å°‡ `data/` è³‡æ–™å¤¾æ”¾ç½®åœ¨å°ˆæ¡ˆæ ¹ç›®éŒ„ä¸‹ã€‚

---

## ç’°å¢ƒè¨­å®š

### ç³»çµ±éœ€æ±‚
- Python 3.12
- CUDA 12.4 (ç”¨æ–¼ GPU åŠ é€Ÿ)
- è‡³å°‘ 16GB GPU è¨˜æ†¶é«” (å»ºè­°ä½¿ç”¨ RTX 3090 æˆ–æ›´é«˜è¦æ ¼)

### å®‰è£ç›¸ä¾å¥—ä»¶

```bash
pip install -r requirements.txt
```

### ä¸»è¦å¥—ä»¶ç‰ˆæœ¬
- `transformers==4.56.1`
- `torch==2.8.0` (with CUDA 12.4 support)
- `sentence-transformers==5.1.0`
- `faiss-gpu-cu12==1.12.0`
- `datasets==4.0.0`

---

## åƒè€ƒè³‡æ–™

1. **Sentence Transformers Documentation**: https://www.sbert.net/
2. **MS MARCO Dataset**: https://microsoft.github.io/msmarco/
3. **E5 Text Embeddings**: https://huggingface.co/intfloat/multilingual-e5-small
4. **Cross-Encoder for Re-Ranking**: https://www.sbert.net/examples/applications/cross-encoder/README.html
5. **MultipleNegativesRankingLoss**: https://www.sbert.net/docs/package_reference/losses.html#multiplenegativesrankingloss

---

## License

æœ¬å°ˆæ¡ˆç‚º NTU ADL 2024 èª²ç¨‹ä½œæ¥­,åƒ…ä¾›æ•™è‚²ç”¨é€”ã€‚
